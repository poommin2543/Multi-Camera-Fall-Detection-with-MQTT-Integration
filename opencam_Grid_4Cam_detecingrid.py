import cv2
import mediapipe as mp
import threading
import numpy as np
import time

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á RTSP
camera_ips = ["192.168.0.11", "192.168.0.12", "192.168.0.13", "192.168.0.14"]
rtsp_urls = [f"rtsp://CamZero:acselab123@{ip}:554/stream1" for ip in camera_ips]
camera_names = ["Camera 1", "Camera 2", "Camera 3", "Camera 4"]

# ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ü‡∏£‡∏°
frame_width, frame_height = 640, 480
num_cameras = len(rtsp_urls)

# Shared variable for frames
frames = [np.zeros((frame_height, frame_width, 3), dtype=np.uint8)] * num_cameras
lock = threading.Lock()

# Fall Detection Tracking
fall_timers = [0] * num_cameras
fall_threshold = 1.5  # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏•‡πâ‡∏°

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Perspective Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡πâ‡∏≠‡∏á
src_points = [
    np.float32([[227, 327], [554, 331], [154, 426], [604, 440]]),  # Camera 1
    np.float32([[586, 328], [71, 324], [511, 187], [141, 179]]),  # Camera 2
    np.float32([[585, 379], [48, 372], [501, 240], [122, 227]]),  # Camera 3
    np.float32([[152, 272], [481, 266], [88, 379], [539, 376]])   # Camera 4
]
dst_pts = np.float32([
    [0, 0], [frame_width, 0], [0, frame_height], [frame_width, frame_height]
])

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Transformation Matrix
perspective_matrices = [cv2.getPerspectiveTransform(src, dst_pts) for src in src_points]
inverse_matrices = [cv2.getPerspectiveTransform(dst_pts, src) for src in src_points]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Grid Points
def get_grid_points(rows=3, cols=6):
    points = []
    step_x = frame_width // cols
    step_y = frame_height // rows
    for i in range(1, cols):
        x = i * step_x
        points.append((x, 0))
        points.append((x, frame_height))
    for i in range(1, rows):
        y = i * step_y
        points.append((0, y))
        points.append((frame_width, y))
    return np.array(points, dtype=np.float32).reshape(-1, 1, 2)

# ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏Å‡∏£‡∏¥‡∏î
def draw_grid(frame, points, color=(0, 255, 0), thickness=1):
    num_points = len(points) // 2
    for i in range(num_points):
        pt1 = tuple(map(int, points[i * 2][0]))
        pt2 = tuple(map(int, points[i * 2 + 1][0]))
        cv2.line(frame, pt1, pt2, color, thickness)
def get_grid_cell(px, py, rows=3, cols=6):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ß‡πà‡∏≤‡∏à‡∏∏‡∏î (px, py) ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏¥‡∏î
    """
    cell_width = frame_width // cols
    cell_height = frame_height // rows

    col = int(px // cell_width) + 1  # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1
    row = int(py // cell_height) + 1  # ‡πÅ‡∏ñ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1

    return row, col

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡πâ‡∏≠‡∏á
fall_detected = [False] * num_cameras  

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß
def process_camera(index, rtsp_url):
    global frames, fall_timers
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose()
    mp_drawing = mp.solutions.drawing_utils

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß
    M = perspective_matrices[index]
    Minv = inverse_matrices[index]
    grid_points = get_grid_points()

    while True:
        cam = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
        cam.set(cv2.CAP_PROP_BUFFERSIZE, 2)

        if not cam.isOpened():
            print(f"‚ö†Ô∏è {camera_names[index]}: Failed to open stream, retrying in 5s...")
            time.sleep(5)
            continue

        while cam.isOpened():
            ret, frame = cam.read()
            if not ret:
                print(f"‚ö†Ô∏è {camera_names[index]}: Connection lost, reconnecting...")
                break

            frame = cv2.resize(frame, (frame_width, frame_height))
            warped_frame = cv2.warpPerspective(frame, M, (frame_width, frame_height))
            original_grid_points = cv2.perspectiveTransform(grid_points, Minv)

            # ‡∏ß‡∏≤‡∏î Grid ‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏°
            draw_grid(warped_frame, grid_points)
            draw_grid(frame, original_grid_points)

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏î‡πâ‡∏ß‡∏¢ MediaPipe Pose
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose.process(rgb_frame)

            processed_frame = frame.copy()
            bbox_color = (0, 255, 0)  # ‡∏™‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á Bounding Box (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß)

            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Bounding Box ‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                x_min = int(min(l.x for l in landmarks) * frame_width)
                y_min = int(min(l.y for l in landmarks) * frame_height)
                x_max = int(max(l.x for l in landmarks) * frame_width)
                y_max = int(max(l.y for l in landmarks) * frame_height)

                # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û
                x_min = max(0, x_min)
                y_min = max(0, y_min)
                x_max = min(frame_width, x_max)
                y_max = min(frame_height, y_max)

                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                cv2.rectangle(processed_frame, (x_min, y_min), (x_max, y_max), bbox_color, 3)

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                # person_center = np.array([[[(x_min + x_max) / 2, (y_min + y_max) / 2]]], dtype=np.float32)
                nose_x = landmarks[mp_pose.PoseLandmark.NOSE].x * frame_width
                nose_y = landmarks[mp_pose.PoseLandmark.NOSE].y * frame_height
                hip_x = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x + landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x) / 2 * frame_width
                hip_y = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].y + landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y) / 2 * frame_height

                person_center = np.array([[[ (nose_x + hip_x) / 2, (nose_y + hip_y) / 2 ]]], dtype=np.float32)
                
                # transformed_center = cv2.perspectiveTransform(person_center, Minv)

                # Debug: ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡∏Å‡∏£‡∏¥‡∏î
                cv2.circle(processed_frame, tuple(map(int, person_center[0][0])), 5, (255, 0, 0), -1)  # ‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                for pt in original_grid_points:
                    cv2.circle(processed_frame, tuple(map(int, pt[0])), 3, (0, 255, 255), -1)  # ‡∏à‡∏∏‡∏î‡∏Å‡∏£‡∏¥‡∏î

                # ‡∏´‡∏≤‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏¥‡∏î‡∏à‡∏≤‡∏Å original_grid_points
                grid_x_min, grid_y_min = np.min(original_grid_points, axis=0)[0]
                grid_x_max, grid_y_max = np.max(original_grid_points, axis=0)[0]

                # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                px, py = person_center[0][0]

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô Grid ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                is_inside_grid = (grid_x_min <= px <= grid_x_max) and (grid_y_min <= py <= grid_y_max)
                # print(is_inside_grid)
                # # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏Å‡∏£‡∏¥‡∏î ‡πÉ‡∏´‡πâ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï fall_timers ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
                if not is_inside_grid:
                    fall_timers[index] = 0  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï Timer
                    with lock:
                        frames[index] = processed_frame  # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ü‡∏£‡∏°‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
                    continue


                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
                nose_y = landmarks[mp_pose.PoseLandmark.NOSE].y * frame_height
                hip_y = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].y + 
                         landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y) / 2 * frame_height

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
                if abs(nose_y - hip_y) < 80:  # ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏°‡∏π‡∏Å‡πÅ‡∏•‡∏∞‡∏™‡∏∞‡πÇ‡∏û‡∏Å‡∏™‡∏±‡πâ‡∏ô ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏°
                    if fall_timers[index] == 0:
                        fall_timers[index] = time.time()
                    elif time.time() - fall_timers[index] > fall_threshold:
                        bbox_color = (0, 0, 255)  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏î‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
                        cv2.rectangle(processed_frame, (x_min, y_min), (x_max, y_max), bbox_color, 3)
                        cv2.putText(processed_frame, "LYING DETECTED!", (x_min, y_min - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA)
                        # ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°
                        if not fall_detected[index]:
                            print(f"üö® ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: ‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°‡∏à‡∏≤‡∏Å {camera_names[index]}")
                            fall_detected[index] = True  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏¢‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß
                else:
                    fall_timers[index] = 0  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï Timer ‡∏ñ‡πâ‡∏≤‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏¢‡∏∑‡∏ô
                    fall_detected[index] = False  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô

            with lock:
                frames[index] = processed_frame

        cam.release()
        time.sleep(2)


threads = [threading.Thread(target=process_camera, args=(i, rtsp_urls[i]), daemon=True) for i in range(num_cameras)]
for t in threads: t.start()

while True:
    with lock:
        top_row = np.hstack((frames[0], frames[1]))
        bottom_row = np.hstack((frames[2], frames[3]))
        combined_frame = np.vstack((top_row, bottom_row))

    cv2.imshow("Multi-Camera View with Grid & Fall Detection", combined_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()
